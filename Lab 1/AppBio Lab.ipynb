{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                            Applied BioInformatics Assignment 2017:\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                    # Module 2: Python Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random DNA sequence\n",
    "\n",
    "\n",
    "Question: Which function do you find most useful for this assignment?\n",
    "Answer : The choice function in the random module for doing sampling with replacement.\n",
    "\n",
    "Question: What distribution do you want for the nucleotides?\n",
    "Answer: In equilibrium conditions (without mutational or selective >pressure and with nucleotides randomly distributed within the genome) there is an equal frequency of the four DNA bases (Adenine, Guanine, Thymine, and Cytosine) on both single >strands of a DNA molecule.(Wikipedia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  23\n",
      "\n",
      "\n",
      ">myrandomsequence\n",
      "CTCCTAGACAGATTTAAATACTG\n"
     ]
    }
   ],
   "source": [
    "#Random DNA Sequence:\n",
    "import random\n",
    "\n",
    "#A list of possible nucleotides\n",
    "list_of_nucleotides = ['A','T','G','C']\n",
    "\n",
    "#Input the sequence length and makes the input (string) into an integer\n",
    "length = int(input('Length:  '))\n",
    "\n",
    "#Empty string used for the sequence\n",
    "sequence = ''\n",
    "\n",
    "#For loop, iterates for the length of the sequence\n",
    "for i in range(0, length):\n",
    "\n",
    "    #Adds a random integer to the sequence string\n",
    "    sequence += random.choice(list_of_nucleotides)\n",
    "\n",
    "#Prints the sequence\n",
    "print(\"\\n\")\n",
    "print(\">myrandomsequence\")\n",
    "print(sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading Stockholm Files:\n",
    "    \n",
    "  Question: Explain the general structure of a Stockholm file. What is an \"accession\"?\n",
    "  Answer: The \"Stockholm\" format is a system for marking up features in a multiple alignment\n",
    "\n",
    "    1. Header: The first line in the file must contain a format and version identifier.\n",
    "    #STOCKHOLM 1.0\n",
    "    2. Sequence Alignment: In the form of <seqname> <aligned sequence> where \"//\" line indicates the end of the   alignment.\n",
    "    3.Alignment Markup: #=GC,#=GF\n",
    "\n",
    "    Accession number:  Accession number are the stable identifiers \n",
    "       for each Pfam family indicating which family it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "LAR_DROME/418-503\n",
      "TENA_CHICK/1495-1571\n",
      "KALM_CHICK/544-641\n",
      "LAR_DROME/710-800\n",
      "PTP99_DROME/172-259\n",
      "IL7RA_HUMAN/130-218\n",
      "TIE2_HUMAN/445-529\n",
      "TIE1_HUMAN/447-533\n",
      "PTPRK_MOUSE/291-376\n",
      "PTP10_DROME/218-301\n",
      "PTP10_DROME/124-205\n",
      "FINC_BOVIN/1635-1713\n",
      "FINC_BOVIN/1176-1257\n",
      "FINC_BOVIN/1907-1984\n",
      "FINC_RAT/1267-1346\n",
      "FINC_BOVIN/909-987\n",
      "FINC_BOVIN/1360-1439\n",
      "FINC_BOVIN/1815-1893\n",
      "TENA_CHICK/683-767\n",
      "TENA_CHICK/775-853\n",
      "FINC_BOVIN/1451-1529\n",
      "TENA_CHICK/1318-1395\n",
      "TENA_CHICK/594-671\n",
      "TENA_CHICK/957-1033\n",
      "TENA_CHICK/865-945\n",
      "FINC_BOVIN/1541-1622\n",
      "FINC_BOVIN/1996-2074\n",
      "TENA_CHICK/1407-1483\n",
      "PTP69_DROME/333-425\n",
      "FINC_BOVIN/813-890\n",
      "FINC_BOVIN/722-800\n",
      "PTPRB_HUMAN/1356-1434\n",
      "PTP10_DROME/406-485\n",
      "PTPRB_HUMAN/468-543\n",
      "PTP10_DROME/313-394\n",
      "PTPRB_HUMAN/113-192\n",
      "PTPRB_HUMAN/644-725\n",
      "PTPRB_HUMAN/732-808\n",
      "PTPRB_HUMAN/908-984\n",
      "PTPRB_HUMAN/996-1074\n",
      "PTPRB_HUMAN/555-632\n",
      "PTPRB_HUMAN/1086-1162\n",
      "PTPRB_HUMAN/1174-1250\n",
      "PTPRB_HUMAN/1262-1344\n",
      "PTP10_DROME/865-939\n",
      "PTP10_DROME/584-661\n",
      "NGCA_CHICK/702-794\n",
      "CNTN2_CHICK/604-692\n",
      "MYPC2_CHICK/632-717\n",
      "MPSF_CHICK/700-785\n",
      "MPSF_CHICK/802-887\n",
      "MPSF_CHICK/372-457\n",
      "MPSF_CHICK/500-585\n",
      "MYPC2_CHICK/925-1006\n",
      "F4H3U7_CELFA/652-733\n",
      "MYLK_CHICK/1319-1403\n",
      "MPSF_CHICK/601-684\n",
      "NRCAM_CHICK/624-709\n",
      "LAR_DROME/323-404\n",
      "NCAM1_BOVIN/611-691\n",
      "NCAM1_BOVIN/510-597\n",
      "FINC_BOVIN/610-692\n",
      "PTPRB_HUMAN/24-103\n",
      "TIE2_HUMAN/640-724\n",
      "PTP69_DROME/237-321\n",
      "TENA_CHICK/1228-1306\n",
      "TENA_CHICK/1046-1124\n",
      "TENA_HUMAN/1257-1335\n",
      "TENA_CHICK/1137-1215\n",
      "TENA_HUMAN/1530-1608\n",
      "EPHB2_CHICK/327-422\n",
      "EPHA3_CHICK/326-421\n",
      "EPHA1_HUMAN/334-431\n",
      "EPHA2_HUMAN/330-419\n",
      "7LESS_DROVI/1918-1997\n",
      "TIE2_HUMAN/544-626\n",
      "KALM_CHICK/178-269\n",
      "LAR_DROME/516-598\n",
      "PTPRZ_HUMAN/313-401\n",
      "EPHA2_HUMAN/437-519\n",
      "TIE1_HUMAN/645-729\n",
      "ITB4_HUMAN/1529-1612\n",
      "ITB4_HUMAN/1221-1310\n",
      "ITB4_HUMAN/1642-1728\n",
      "PTP10_DROME/959-1044\n",
      "EPHB2_CHICK/438-521\n",
      "EPHA4_MOUSE/442-525\n",
      "LAR_DROME/911-995\n",
      "NRCAM_CHICK/929-1014\n",
      "7LESS_DROME/1800-1891\n",
      "E1JJF8_DROME/918-1007\n",
      "ITB4_HUMAN/1128-1208\n",
      "UFO_HUMAN/335-418\n",
      "E1JJF8_DROME/817-905\n",
      "CNTN2_CHICK/809-896\n",
      "CNTN1_CHICK/801-884\n",
      "TIE1_HUMAN/547-632\n",
      "L1CAM_HUMAN/813-907\n"
     ]
    }
   ],
   "source": [
    "file_1 = \"PF.sthlm\"\n",
    "file_2 = \"file_comment.sthlm\"\n",
    "file_3 = \"file.sthlm\"\n",
    "#Opens and reads the file\n",
    "f = open(file_1, 'r')\n",
    "\n",
    "output = []\n",
    "\n",
    "for line in f:\n",
    "    if line[0] == \"#\" or line[0:2]==\"//\" or len(line)<2:\n",
    "        continue\n",
    "    else:\n",
    "        output_seq = line.split(' ')[0] #default is whitesapce\n",
    "        output.append(output_seq)\n",
    "print (len(output))\n",
    "for i in output:\n",
    "    print (i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Re-formatting sequences\n",
    "##### Reads sequences from Stockholm filesand re-format the sequences into Fasta format\n",
    "\n",
    "Question:  What is Pfam?\n",
    "\n",
    "Answer:Pfam is a database of protein families that includes their annotations and multiple sequence alignments.\n",
    "\n",
    "Four test cases files: \n",
    "                    1. longseqs.sthlm\n",
    "                    2. cornercase.sthlm\n",
    "                    3. shortseqs.sthlm\n",
    "                    4. PF00041.sthlm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which sequence file? : longseqs.sthlm\n",
      ">gene4711\n",
      "ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n",
      "ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n",
      ">hubba\n",
      "ACGTACGTACGTACGTACGTACGTANNNNNNNNNNTACGTACGTACGTACGTACGTACGT\n",
      "ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n",
      "T\n",
      ">gene4712\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
      "GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\n",
      "TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n"
     ]
    }
   ],
   "source": [
    "def reformat(content,sequence):\n",
    "    #first line with name, add >\n",
    "    header = \">\" + content\n",
    "    print (header)\n",
    "    \n",
    "    for i in range(0,len(sequence),60):\n",
    "        print (sequence[i:i+60])\n",
    "\n",
    "\n",
    "file = input(\"Which sequence file? : \")\n",
    "f = open(file, 'r')\n",
    "\n",
    "for line in f:\n",
    "    content = \"\"\n",
    "    sequence = \"\"\n",
    "    #Removes all lines that starts with hash, // and empty lines\n",
    "    if line[0] == \"#\" or line[0] == \"\\n\" or line[0:2] == \"//\":\n",
    "        a = 1\n",
    "    else:\n",
    "        content_seq = line.split()\n",
    "        content = content_seq[0]\n",
    "\n",
    "        if len(content_seq) == 2:\n",
    "            sequence = content_seq[1]\n",
    "\n",
    "        reformat(content, sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Translate DNA \n",
    "\n",
    "###### Question: What are the \"stop codons\" in the standard code?\n",
    " Stop codons are a trimmer of basepairs which indicates the end of a gene. TGA, TAG and TAA\n",
    "\n",
    "###### Question: Why are we talking about a \"standard code\"?\n",
    "Standard code means that how most organisms have their codons and all organisms have this table.We have non-standard amino acids and variations, giving other results and stop codons.\n",
    "\n",
    "###### Question: Looking for the longest ORF is a primitive way to find genes in prokaryotic genomes.Why does it not work for eukaryotes?\n",
    "The main problem with the genomes of higher eukaryotes in general is that their genes are often split by introns, and so do not appear as continuous ORFs in the DNA sequence\n",
    "\n",
    "###### Question: What is the longest protein snippet produced on the file an_exon.fa?\n",
    "111\n",
    "\n",
    "###### Question: Why should a real ORF finder also look at the so-called Watson-Crick complement?\n",
    "Watson Crick complement is a string representing the complementary DNA strand (T <-> A, G <-> C). Need to look at this as well to get whole helix\n",
    "\n",
    "#### Input Files:\n",
    "        1. translationtest.dna\n",
    "        2. an_exon.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which file do you want to open? an_exon.fa\n",
      "> <ipython-input-9-c949e3b532ff>(83)<module>()\n",
      "-> result = result+lines[processed_input_lines[j]].split(' ')[0].split('\\n')[0]+'\\n'\n",
      "(Pdb) l\n",
      " 78  \tprocessed_input_lines = read_fasta_file(file)\n",
      " 79  \t#print (\"processed_input_lines : -------  \",processed_input_lines)\n",
      " 80  \tfor j in range(0,len(processed_input_lines)-1):\n",
      " 81  \t    str_list = []\n",
      " 82  \t    pdb.set_trace()\n",
      " 83  ->\t    result = result+lines[processed_input_lines[j]].split(' ')[0].split('\\n')[0]+'\\n'\n",
      " 84  \t   # print (\"output : ----\", output)\n",
      " 85  \t    string = ''\n",
      " 86  \t    seq = create_sequence(processed_input_lines,lines,j)\n",
      " 87  \t    #print (\"sequence: \",seq)\n",
      " 88  \t    str_list = generate_stringlist(seq,string)\n",
      "(Pdb) l\n",
      " 89  \t    longest_orf = max(str_list,key=len)\n",
      " 90  \t    print ()\n",
      " 91  \t    longest_orf = longest_orf.split('\\n')[0]\n",
      " 92  \t        #pdb.set_trace()\n",
      " 93  \t    amino = generate_amino(longest_orf,amino_conversion_dictionary)\n",
      " 94  \t    result = result+amino+'\\n'\n",
      " 95  \tprint(result)\n",
      " 96  \t\n",
      "[EOF]\n",
      "(Pdb) continue\n",
      "\n",
      ">where_is_the_exon\n",
      "GTWVKEGGFIFGLVQPCTQASGCLDPSPTWPAPQTLCVKAVVPFPWGPSSVFFLPLQVSKVVQFPPCSLLFFLVHEWHPLKAGRYKGLPHAWGGAGGGNDAIAPCWPAWPT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pdb #PDB: Bonus task -> python debugger module\n",
    "\n",
    "def read_fasta_file(input):\n",
    "    processed_input_lines=[]\n",
    "    #print (\"length of lines :\", len(lines))\n",
    "    \n",
    "    for i in range(0,len(lines)): \n",
    "        line = file.readline()\n",
    "        if line.startswith('>'):\n",
    "            processed_input_lines.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    processed_input_lines.append(len(lines))\n",
    "    return processed_input_lines\n",
    "\n",
    "def create_sequence(processed_input_lines,lines,j):\n",
    "    seq=''\n",
    "    for i in range(processed_input_lines[j]+1,processed_input_lines[j+1]):\n",
    "        seq=seq+lines[i][:-1] #sequence of 60\n",
    "        #print (\"sequence : >>>\", seq)\n",
    "    return seq\n",
    "\n",
    "def prepare_string_of_codons(section,string,str_list):\n",
    "    for m in range(0,int(math.floor(len(section)/3+1))):\n",
    "        part = section[3*m:3*m+3]\n",
    "        #print (\"Codons %s read in iteration %s \" %(part,m))\n",
    "        #if len(part)<3:\n",
    "            #break\n",
    "        if part=='TGA' or part=='TAA' or part=='TAG' or part=='tga' or part=='tag' or part=='taa':\n",
    "            str_list.append(string)\n",
    "            string=''\n",
    "        else:\n",
    "            string=string+part\n",
    "    return string\n",
    "\n",
    "def generate_stringlist(seq,string):\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        section = seq[i:].split('\\n')[0] # Reads the entire sequence\n",
    "        #print (\"section is here :\", section)\n",
    "        if len(section)<3:\n",
    "            string=''\n",
    "            str_list.append(string)\n",
    "            break\n",
    "        string = prepare_string_of_codons(section,string,str_list)\n",
    "        str_list.append(string)\n",
    "        string=''\n",
    "    return str_list\n",
    "\n",
    "def generate_amino(longest,amino_conversion_dictionary):\n",
    "    amino=''\n",
    "    for n in range(0,int(math.floor(len(longest)/3))):\n",
    "        var_codon = longest_orf[3*n:3*n+3]\n",
    "        var_codon = var_codon.upper()\n",
    "        if 'A' in var_codon or 'T' in var_codon or 'C' in var_codon or 'G' in var_codon:\n",
    "            amino=amino+amino_conversion_dictionary[var_codon]\n",
    "        else:\n",
    "            amino=amino+'X'\n",
    "    return amino\n",
    "\n",
    "amino_conversion_dictionary = {'GCT':'A', 'GCC':'A', 'GCA':'A','GCG':'A', 'CGT':'R', 'CGC':'R',\n",
    "    'CGA':'R', 'CGG':'R', 'AGA':'R', 'AGG':'R', 'AAT':'N', 'AAC':'N', 'GAT':'D',\n",
    "    'GAC':'D', 'TGT':'C', 'TGC':'C', 'CAA':'Q', 'CAG':'Q', 'GAA':'E', 'GAG':'E',\n",
    "    'GGT':'G', 'GGC':'G', 'GGA':'G', 'GGG':'G', 'CAT':'H', 'CAC':'H', 'ATT':'I',\n",
    "    'ATC':'I', 'ATA':'I', 'TTA':'L', 'TTG':'L', 'CTT':'L', 'CTC':'L', 'CTA':'L',\n",
    "    'CTG':'L', 'AAA':'K', 'AAG':'K', 'ATG':'M', 'TTT':'F', 'TTC':'F', 'CCT':'P',\n",
    "    'CCC':'P', 'CCA':'P', 'CCG':'P', 'TCT':'S', 'TCC':'S', 'TCA':'S', 'TCG':'S',\n",
    "    'AGT':'S', 'AGC':'S', 'ACT':'T', 'ACC':'T', 'ACA':'T', 'ACG':'T', 'TGG':'W',\n",
    "    'TAT':'Y','TAC':'Y', 'GTT':'V', 'GTC':'V', 'GTA':'V', 'GTG':'V'}\n",
    "\n",
    "\n",
    "filename = input('Which file do you want to open? ')\n",
    "file = open(str(filename),'r')\n",
    "lines = file.readlines()\n",
    "result=''\n",
    "file = open(str(filename),'r')\n",
    "processed_input_lines = read_fasta_file(file)\n",
    "#print (\"processed_input_lines : -------  \",processed_input_lines)\n",
    "for j in range(0,len(processed_input_lines)-1):\n",
    "    str_list = []\n",
    "    pdb.set_trace()\n",
    "    result = result+lines[processed_input_lines[j]].split(' ')[0].split('\\n')[0]+'\\n'\n",
    "   # print (\"output : ----\", output)\n",
    "    string = ''\n",
    "    seq = create_sequence(processed_input_lines,lines,j)\n",
    "    #print (\"sequence: \",seq)\n",
    "    str_list = generate_stringlist(seq,string)\n",
    "    longest_orf = max(str_list,key=len)\n",
    "    print ()\n",
    "    longest_orf = longest_orf.split('\\n')[0]\n",
    "        #pdb.set_trace()\n",
    "    amino = generate_amino(longest_orf,amino_conversion_dictionary)\n",
    "    result = result+amino+'\\n'\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Basic Python: Advanced assignment\n",
    "\n",
    "\n",
    "## PDB: Python Debugger Module\n",
    "\n",
    "Can be illustrated by uncommenting the import pdb and pdb.set_trace() command in the above module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
